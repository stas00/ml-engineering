# README - 中文翻译

# CPU内存

这是一小节，因为通常关于CPU内存需要了解的细节很少——这是件好事！

大多数机器学习工作负载的计算发生在GPU上，但每个节点上的CPU内存至少应该与GPU上的内存一样多。例如，如果你在一个拥有8个80GB GPU的H100节点上，那么你有640GB的GPU内存。因此，你需要至少同样多的CPU内存。但最近的高端云服务包通常会提供1-2TB的CPU内存。

## 在机器学习负载中CPU内存的作用

- 加载模型权重，除非它们直接加载到GPU上——这通常是临时的内存使用，在模型被移动到GPU后会回到零。
- 保存模型权重。在某些情况下，每个GPU会直接将检查点写入磁盘；而在其他情况下，模型会在写入磁盘前在CPU上重组——这也是临时的内存使用。
- 使用像[DeepSpeed](https://www.deepspeed.ai/tutorials/zero-offload/)这样的框架时，可能需要将参数和优化器状态卸载到CPU上。在这种情况下，可能需要大量的CPU内存。
- 在`forward`过程中计算的激活值，为了在`backward`过程中可用，也可以卸载到CPU上，而不是在反向传播过程中丢弃并重新计算以节省不必要的开销。
- `DataLoader`通常是CPU内存的主要使用者之一，有时可能会消耗大量内存。通常每个节点至少运行2个8个DL工作者，因此你需要足够的内存来支持至少16个进程，每个进程都持有部分数据。例如，在从云端流式传输数据的情况下，如果数据分片很大，这些进程很容易消耗掉数百GB的CPU内存。
- 软件本身及其依赖库也会占用一些CPU内存，但这个量通常可以忽略不计。

## 需要知道的事项

- 如果`DataLoader`使用HF `datasets`的`mmap`模式，驻留内存的使用可能会显示CPU内存使用量巨大，因为它会尝试将整个数据集映射到内存中。但实际上这是误导性的，因为如果内存需要在其他地方使用，操作系统会将不需要的`mmap`页面分页回系统。你可以在这里阅读更多相关信息：[这里](https://stasosphere.com/entrepreneur-being/301-mmap-memory-leak-investigation/)。当然，这种认识适用于任何使用`mmap`的数据集。我用HF `datasets`作为例子，因为它非常常用。