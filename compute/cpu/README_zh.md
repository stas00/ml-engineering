# README - 中文翻译

# CPU

截至撰写本文时，机器学习工作负载对CPU的使用不多，因此本章中没有太多内容可讲述。随着CPU逐渐向GPU发展，这种情况可能会改变，因此预计本章会随着CPU的发展而演变。

## 需要多少个CPU核心

每有一个加速器，你需要：

1. 每个绑定到加速器的进程需要1个CPU核心。
2. 每个`DataLoader`工作进程需要1个CPU核心——通常你需要2到4个工作进程。

对于语言模型（LMs），两个工作进程通常已经足够，特别是如果数据已经被预处理过。

如果你需要进行动态变换，这在计算机视觉模型或VLMs中很常见，你可能需要3到4个工作进程，有时甚至更多。

目标是能够从`DataLoader`即时获取数据，并且不会阻塞加速器的计算，这意味着你需要预先处理一批样本以便在当前迭代运行时使用。换句话说，你的下一个批次的处理时间不应超过同大小批次的加速器计算时间。

除了预处理外，如果你是从云存储而不是本地存储动态拉取数据，还需要确保数据预取得足够快，以满足工人的需求。

将上述需求乘以加速器的数量，并加上几个用于操作系统的内核（假设为4个）。

如果节点有8个加速器，并且你有n_workers，那么你需要`8*(num_workers+1)+4`个内核。如果你做的是NLP任务，通常每个加速器需要约2个工作进程，即`8*(2+1)+4`=> 28个CPU核心。如果你做的是计算机视觉训练，并且每个加速器需要4个工作进程，那么就是`8*(4+1)+4`=> 44个CPU核心。

如果你拥有的非常活跃的进程数量超过了总CPU核心数会发生什么？一些进程会被抢占（放入队列，等待CPU核心可用时再执行），你绝对不希望出现任何上下文切换。

但现代云服务通常提供50-100多个CPU核心，所以通常不会有足够的核心不足的问题。

参见[异步DataLoader](../../training/performance#asynchronous-dataloader)。

### CPU卸载

一些框架，如[Deepspeed](https://www.deepspeed.ai/tutorials/zero-offload/)，可以在不造成瓶颈的情况下将一些计算工作卸载到CPU上。在这种情况下，你可能需要额外的CPU核心。

### NUMA亲和性

参见[NUMA亲和性](../../training/performance#numa-affinity)。

### 超线程

[超线程](https://en.wikipedia.org/wiki/Hyper-threading)通过将每个物理核心虚拟化为两个虚拟核心，使每个物理核心可以同时运行两个线程，从而将CPU核心数量翻倍。根据工作负载类型，此功能可能会也可能不会提高整体性能。该技术的发明者英特尔建议，在某些情况下，性能可能提高30%。

参见[是否启用超线程](../../orchestration/slurm/performance.md#to-enable-hyper-threads-or-not)。