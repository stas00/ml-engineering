# README - 中文翻译

# 软件调优以获得最佳性能

训练模型的速度越快，模型完成训练的时间就越短，这不仅对于率先发布某些内容很重要，还可以节省大量成本。

一般来说，最大化吞吐量就是运行大量的实验并测量结果，然后选择表现更优的配置。

在某些情况下，您的建模团队可能会要求您选择一些超参数，这些参数虽然会损害吞吐量，但总体上对整个模型的成功有益。


## 术语和概念

- HFU：硬件浮点运算利用率
- MFU：模型浮点运算利用率

### MACs、FLOP、FLOPS 和 FLOP/s 的区别

本节旨在澄清常见的性能指标定义及其相互关系。

**MAC与FLOP的区别**：

- 1个FLOP（浮点运算）可以是加法、减法、乘法或除法操作中的一个。

- 1个MAC（乘积累加）操作是由一次乘法后跟一次加法组成，即：`a * b + c`

因此，1个MAC等于2个FLOP。现代硬件通常可以在单个时钟周期内执行1个MAC。

请注意，计算MAC与FLOP的关系时，逻辑是相反的，即MACs = 0.5 FLOPs —— 这可能有点令人困惑，因为我们刚刚说过1个MAC等于2个FLOP，但这确实是正确的——观察：100 FLOPs = 50 MACs，因为每个MAC中有2个FLOP。

此外，虽然1个MAC等于2个FLOP，但反过来并不一定成立。也就是说，2个FLOP不一定等于1个MAC。例如，如果你重复执行`.5*.6` 100次，总共会有100个FLOP，这里相当于100个MAC，因为这里只执行了MAC中的乘法部分。

**FLOP、FLOPS 与 FLOP/s的区别**

- 1个FLOP（浮点运算）是任何浮点加法、减法、乘法或除法运算。

- 1个FLOPS（每秒浮点运算次数）是在1秒内执行了多少浮点运算——见[FLOPS](https://en.wikipedia.org/wiki/FLOPS)

此外，你会看到以下缩写：GFLOPS = 吉浮点运算每秒，TFLOPS = 太浮点运算每秒等，因为这样更容易快速理解150TFLOPS而不是150000000000000FLOPS。

当写作中使用FLOPS时存在歧义——有时人们用它来表示总的运算数量，而在其他时候它指的是每秒的运算次数。后者是最常见的用法，这也是本书中使用的定义。

在科学写作中，FLOP/s通常被用来明确告诉读者这是每秒的运算次数。尽管这种特定的方法在转换为变量名时仍然会变成`flops`，因为它仍然变成了`flops`。

在某些地方你也可能会看到FLOPs，这同样可能是两者之一，因为它很容易将大小写`s`翻转。

如果定义不明确，请尝试搜索上下文，这有助于推导出所指的内容：

- 如果是一个数学方程并且有时间除法，那么知道这是每秒的运算次数。
- 如果讨论速度或性能，通常指的是每秒的运算次数。
- 如果谈论完成某项任务所需的计算量，则指的是总的运算次数。


### TFLOPS作为性能指标

在开始优化你的训练设置之前，你需要一个度量标准，以便能够看出吞吐量是否有所改善。你可以测量每次迭代所需的时间，或者每次迭代的次数，或者其他类似的计时方法，但是有一个更有用的指标，即测量TFLOPS。

测量TFLOPS优于其他方法，因为它使你知道自己是否接近所能达到的最佳性能。这个测量值为你提供了与硬件制造商报告的峰值性能之间的距离。

在这一部分中，我将以BLOOM的训练为例进行说明。我们使用了80GB的A100 NVIDIA GPU，并且我们在混合bf16模式下进行了训练。让我们看一下[A100规格](https://www.nvidia.com/en-us/data-center/a100/)，其中告诉我们：

```
BFLOAT16 Tensor Core 	312 TFLOPS
```

因此我们现在知道，如果我们仅在巨大的bf16矩阵上运行`matmul`而不进行设备之间的复制，我们应该能达到大约312 TFLOPS的最大值。

然而，由于磁盘I/O、通信以及将数据从GPU内存复制到其计算单元的开销，实际上我们期望的远低于此。实际值将因加速器而异，但对于2022年的A100，在复杂的384个GPU训练设置中达到50%以上（155 TFLOPS）被认为是一个惊人的可持续吞吐量。

注脚：2023年，闪存注意力和其他技术的发明将门槛提升到了50%以上。

当我们刚开始调整时，我们的吞吐量小于100 TFLOPS，几周后我们启动训练时达到了150 TFLOPS。

需要注意的重要一点是，我们知道我们无法进一步提高很多，并且我们也知道没有更多优化的意义了。

因此，当准备进行大规模模型训练时的一个一般经验法则是——询问可以获得的最大TFLOPS是多少，然后优化直到接近该数值。一旦达到这个点就停止优化并开始训练。

注脚：2022年80GB A100的最高值为155，2023年已提升至约180 TFLOPS。

注脚：计算TFLOPS时要记住，如果启用了[梯度检查点](#梯度检查点)，则数学计算会有所不同，因为激活重计算功能会增加计算量，需要考虑进去。通常代价是额外的前向路径，但最近找到了一些更好的方法来减少这部分的重新计算。

对于解码器变换模型，下面是一个估计公式，略微低估了真实的TFLOPS：

TFLOPS：`model_size_in_B * 4 * 2 * seqlen * global_batch_size / (time_in_sec_per_interation * total_gpus * 1e3)`

激活/梯度检查点启用时使用4，否则为3。对于超过100B的模型，几乎总是启用激活检查点。

因此，`3*2`通常称为“模型FLOPs”，`4*2`——“硬件FLOPs”，对应于MFU和HFU（每秒模型和硬件FLOPS除以加速器理论峰值FLOPS）

```perl
perl -le '$ng=64; $ms=52; $gbs=1024; $sp=127; $seqlen=2048; print $ms*4*2*$seqlen*$gbs / ( $sp * $ng * 1e3)'
```
（ng=总GPU数，ms=模型大小（B），gbs=全局批量大小，sp=每次迭代的耗时（秒））

这里使用`bash`环境变量，并将其分解为`MBS*DP*GAS`（在这种情况下，GAS对应于`pp_chunks`，即管道中的块数，但通常GAS代表梯度累积步数）：
```bash
echo "($MSIZE*4*2*SEQLEN*$MICRO_BATCH_SIZE*$DP_SIZE*$GAS)/($THROUGHPUT*$NNODES*4*1000)" | bc -l
```

确切的公式在[高效的大规模语言模型训练论文](https://arxiv.org/abs/2104.04473)的第5.1节的等式3中。你可以在这里查看代码：[链接](https://github.com/bigscience-workshop/Megatron-DeepSpeed/pull/251)。

注脚：仅用于推理的话，每层的浮点运算次数为：`24Bsh^2 + 4Bs^2h`


#### 自动化FLOP计算

直到最近，我们还必须依靠手动计算FLOP，如上一节所述——许多这些公式都有错误，而且许多模型根据各种配置设置的行为也不同。因此，正确地得到FLOP计数（尤其是在多种不同的模型架构之间）可能很棘手。但不必担心，出色的PyTorch团队开发了一种自动测量FLOPs的方法。

```python
from torch.utils.flop_counter import FlopCounterMode

flop_counter = FlopCounterMode(mods=model, display=False, depth=None)
with flop_counter:
    model(**input).sum().backward()
total_flops =  flop_counter.get_total_flops()
```
现在，FLOPs已经为你计算好了！

在我的代码中，我只在第二次迭代时运行它（第一次迭代很可能包含一些仅运行一次的额外计算）。你不需要重复运行它，你可以缓存它的值（除非你有某种原因导致每次迭代都不相同的情况）。

所以剩下的就是测量每次特定迭代所需的时间，然后将FLOPs除以时间（秒）并除以`1e12`得到性能TFLOPS。

```python
tflops = total_flops / time / 1e12
```

这将在每次迭代时给出略有不同的值。